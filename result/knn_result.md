# CIFAR-10 KNN 분류 과제 결과

**참고**: 이 실험은 빠른 실행을 위해 데이터의 일부만 사용했습니다.
- 학습 샘플: 5000개
- 테스트 샘플: 1000개
- PCA 적용: Yes (차원: 3072 → 200)

## Task 1: Train/Test Split만 사용한 KNN 분류

### 설정
- k 값: 5
- 학습 데이터: 5000개 샘플
- 테스트 데이터: 1000개 샘플

### 성능 지표

| 지표 | 점수 |
|--------|-------|
| Accuracy | 0.2780 |
| Precision (macro) | 0.3457 |
| Recall (macro) | 0.2780 |
| F1-Score (macro) | 0.2668 |

## Task 2: Train/Validation/Test Split을 사용한 하이퍼파라미터 튜닝

### 설정
- 학습 데이터: 4250개 샘플 (85%)
- 검증 데이터: 750개 샘플 (15%)
- 테스트 데이터: 1000개 샘플

### 검증 결과

| k | 검증 정확도 |
|---|---------------------|
| 1 | 0.2760 |
| 3 | 0.2680 |
| 5 | 0.2733 |
| 7 | 0.2800 |
| 9 | 0.2613 |
| 11 | 0.2573 |
| 13 | 0.2533 |
| 15 | 0.2627 |

**최적 k 값: 7**

### 최적 k로 테스트 세트 평가

| 지표 | 점수 |
|--------|-------|
| Accuracy | 0.2750 |
| Precision (macro) | 0.3605 |
| Recall (macro) | 0.2750 |
| F1-Score (macro) | 0.2609 |

## Task 3: 5-Fold Cross-Validation

### 설정
- Fold 수: 5
- Fold당 학습 데이터: 4000개 샘플
- Fold당 검증 데이터: 1000개 샘플

### Cross-Validation 결과

| k | Accuracy | Precision | Recall | F1-Score |
|---|----------|-----------|--------|----------|
| 1 | 0.2730 ± 0.0177 | 0.3099 ± 0.0153 | 0.2737 ± 0.0161 | 0.2645 ± 0.0156 |
| 3 | 0.2616 ± 0.0086 | 0.3379 ± 0.0133 | 0.2621 ± 0.0065 | 0.2464 ± 0.0074 |
| 5 | 0.2694 ± 0.0110 | 0.3436 ± 0.0135 | 0.2689 ± 0.0087 | 0.2516 ± 0.0096 |
| 7 | 0.2714 ± 0.0093 | 0.3563 ± 0.0096 | 0.2714 ± 0.0070 | 0.2492 ± 0.0098 |
| 9 | 0.2780 ± 0.0145 | 0.3563 ± 0.0125 | 0.2782 ± 0.0110 | 0.2523 ± 0.0126 |
| 11 | 0.2802 ± 0.0167 | 0.3699 ± 0.0168 | 0.2805 ± 0.0128 | 0.2540 ± 0.0138 |
| 13 | 0.2812 ± 0.0186 | 0.3655 ± 0.0243 | 0.2811 ± 0.0148 | 0.2547 ± 0.0191 |
| 15 | 0.2780 ± 0.0229 | 0.3603 ± 0.0294 | 0.2783 ± 0.0192 | 0.2493 ± 0.0209 |
| 17 | 0.2782 ± 0.0208 | 0.3680 ± 0.0325 | 0.2790 ± 0.0160 | 0.2487 ± 0.0199 |
| 19 | 0.2786 ± 0.0239 | 0.3692 ± 0.0280 | 0.2791 ± 0.0185 | 0.2471 ± 0.0220 |
| 21 | 0.2766 ± 0.0213 | 0.3793 ± 0.0256 | 0.2773 ± 0.0152 | 0.2439 ± 0.0181 |

**최고 성능 k 값: 13** (Accuracy: 0.2812)

### Accuracy vs. k 그래프

![Accuracy vs k](result/cv_accuracy_vs_k.png)

## 분석 및 결론

### 주요 발견사항

1. **최적 k 값**: Validation split 방법에서는 k=7가 최적이었고, 5-fold CV에서는 k=13이 최고 성능을 보였습니다.

2. **성능 비교**:
   - Task 1 (k=5): Accuracy = 0.2780
   - Task 2 (k=7): Accuracy = 0.2750
   - Task 3 (k=13): Accuracy = 0.2812

3. **Cross-Validation의 장점**: 5-fold CV는 모델의 안정성과 일반화 성능을 더 신뢰성 있게 평가할 수 있습니다. Error bars는 각 k 값에 대한 성능의 변동성을 보여줍니다.

4. **PCA의 효과**: PCA를 적용하여 차원을 3072에서 200으로 축소했습니다. 이를 통해 노이즈 제거와 계산 속도 향상 효과를 얻었습니다.

5. **k 값의 영향**: k 값이 너무 작으면 overfitting, 너무 크면 underfitting 경향이 있습니다. 그래프를 통해 최적의 균형점을 찾을 수 있습니다.

### CIFAR-10에서 KNN의 한계

KNN은 간단하고 직관적인 알고리즘이지만, CIFAR-10과 같은 복잡한 이미지 데이터셋에는 다음과 같은 한계가 있습니다:

- 픽셀 기반 거리 측정은 의미론적 유사성을 잘 포착하지 못함
- 고차원 데이터에서 'curse of dimensionality' 문제
- CNN과 같은 딥러닝 모델에 비해 낮은 정확도
- 예측 시간이 느림 (모든 학습 데이터와 거리 계산 필요)

